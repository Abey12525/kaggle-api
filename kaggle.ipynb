{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Abey12525/kaggle-api/blob/master/kaggle.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "lSm7BejfaU4b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "3582dd06-18ef-4a7c-929f-0605c12451d2"
      },
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "filename = \"/content/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)\n",
        "\n",
        "\n",
        "\n",
        "!pip install kaggle\n",
        "!kaggle competitions download -c avito-demand-prediction -p /content/kaggle"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download 100%.\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.3.8)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.4.16)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: urllib3>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "sample_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_jpg.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train_jpg.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "periods_test.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "periods_train.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_active.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train_active.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train_jpg_4.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train_jpg_2.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train_jpg_1.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train_jpg_0.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train_jpg_3.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jVdEpEjOxKgE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#data_download "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XFV6pERlQrZb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "4ec2c8f6-c7c5-4c4b-a802-9c4c5ef13300"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_csv=pd.read_csv('/content/kaggle/train.csv.zip', compression='zip', header=0, sep=',', quotechar='\"')\n",
        "train_csv.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>region</th>\n",
              "      <th>city</th>\n",
              "      <th>parent_category_name</th>\n",
              "      <th>category_name</th>\n",
              "      <th>param_1</th>\n",
              "      <th>param_2</th>\n",
              "      <th>param_3</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>price</th>\n",
              "      <th>item_seq_number</th>\n",
              "      <th>activation_date</th>\n",
              "      <th>user_type</th>\n",
              "      <th>image</th>\n",
              "      <th>image_top_1</th>\n",
              "      <th>deal_probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b912c3c6a6ad</td>\n",
              "      <td>e00f8ff2eaf9</td>\n",
              "      <td>Свердловская область</td>\n",
              "      <td>Екатеринбург</td>\n",
              "      <td>Личные вещи</td>\n",
              "      <td>Товары для детей и игрушки</td>\n",
              "      <td>Постельные принадлежности</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Кокоби(кокон для сна)</td>\n",
              "      <td>Кокон для сна малыша,пользовались меньше месяц...</td>\n",
              "      <td>400.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2017-03-28</td>\n",
              "      <td>Private</td>\n",
              "      <td>d10c7e016e03247a3bf2d13348fe959fe6f436c1caf64c...</td>\n",
              "      <td>1008.0</td>\n",
              "      <td>0.12789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2dac0150717d</td>\n",
              "      <td>39aeb48f0017</td>\n",
              "      <td>Самарская область</td>\n",
              "      <td>Самара</td>\n",
              "      <td>Для дома и дачи</td>\n",
              "      <td>Мебель и интерьер</td>\n",
              "      <td>Другое</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Стойка для Одежды</td>\n",
              "      <td>Стойка для одежды, под вешалки. С бутика.</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>19</td>\n",
              "      <td>2017-03-26</td>\n",
              "      <td>Private</td>\n",
              "      <td>79c9392cc51a9c81c6eb91eceb8e552171db39d7142700...</td>\n",
              "      <td>692.0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ba83aefab5dc</td>\n",
              "      <td>91e2f88dd6e3</td>\n",
              "      <td>Ростовская область</td>\n",
              "      <td>Ростов-на-Дону</td>\n",
              "      <td>Бытовая электроника</td>\n",
              "      <td>Аудио и видео</td>\n",
              "      <td>Видео, DVD и Blu-ray плееры</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Philips bluray</td>\n",
              "      <td>В хорошем состоянии, домашний кинотеатр с blu ...</td>\n",
              "      <td>4000.0</td>\n",
              "      <td>9</td>\n",
              "      <td>2017-03-20</td>\n",
              "      <td>Private</td>\n",
              "      <td>b7f250ee3f39e1fedd77c141f273703f4a9be59db4b48a...</td>\n",
              "      <td>3032.0</td>\n",
              "      <td>0.43177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>02996f1dd2ea</td>\n",
              "      <td>bf5cccea572d</td>\n",
              "      <td>Татарстан</td>\n",
              "      <td>Набережные Челны</td>\n",
              "      <td>Личные вещи</td>\n",
              "      <td>Товары для детей и игрушки</td>\n",
              "      <td>Автомобильные кресла</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Автокресло</td>\n",
              "      <td>Продам кресло от0-25кг</td>\n",
              "      <td>2200.0</td>\n",
              "      <td>286</td>\n",
              "      <td>2017-03-25</td>\n",
              "      <td>Company</td>\n",
              "      <td>e6ef97e0725637ea84e3d203e82dadb43ed3cc0a1c8413...</td>\n",
              "      <td>796.0</td>\n",
              "      <td>0.80323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7c90be56d2ab</td>\n",
              "      <td>ef50846afc0b</td>\n",
              "      <td>Волгоградская область</td>\n",
              "      <td>Волгоград</td>\n",
              "      <td>Транспорт</td>\n",
              "      <td>Автомобили</td>\n",
              "      <td>С пробегом</td>\n",
              "      <td>ВАЗ (LADA)</td>\n",
              "      <td>2110</td>\n",
              "      <td>ВАЗ 2110, 2003</td>\n",
              "      <td>Все вопросы по телефону.</td>\n",
              "      <td>40000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2017-03-16</td>\n",
              "      <td>Private</td>\n",
              "      <td>54a687a3a0fc1d68aed99bdaaf551c5c70b761b16fd0a2...</td>\n",
              "      <td>2264.0</td>\n",
              "      <td>0.20797</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        item_id       user_id                 region              city  \\\n",
              "0  b912c3c6a6ad  e00f8ff2eaf9   Свердловская область      Екатеринбург   \n",
              "1  2dac0150717d  39aeb48f0017      Самарская область            Самара   \n",
              "2  ba83aefab5dc  91e2f88dd6e3     Ростовская область    Ростов-на-Дону   \n",
              "3  02996f1dd2ea  bf5cccea572d              Татарстан  Набережные Челны   \n",
              "4  7c90be56d2ab  ef50846afc0b  Волгоградская область         Волгоград   \n",
              "\n",
              "  parent_category_name               category_name  \\\n",
              "0          Личные вещи  Товары для детей и игрушки   \n",
              "1      Для дома и дачи           Мебель и интерьер   \n",
              "2  Бытовая электроника               Аудио и видео   \n",
              "3          Личные вещи  Товары для детей и игрушки   \n",
              "4            Транспорт                  Автомобили   \n",
              "\n",
              "                       param_1     param_2 param_3                  title  \\\n",
              "0    Постельные принадлежности         NaN     NaN  Кокоби(кокон для сна)   \n",
              "1                       Другое         NaN     NaN      Стойка для Одежды   \n",
              "2  Видео, DVD и Blu-ray плееры         NaN     NaN         Philips bluray   \n",
              "3         Автомобильные кресла         NaN     NaN             Автокресло   \n",
              "4                   С пробегом  ВАЗ (LADA)    2110         ВАЗ 2110, 2003   \n",
              "\n",
              "                                         description    price  \\\n",
              "0  Кокон для сна малыша,пользовались меньше месяц...    400.0   \n",
              "1          Стойка для одежды, под вешалки. С бутика.   3000.0   \n",
              "2  В хорошем состоянии, домашний кинотеатр с blu ...   4000.0   \n",
              "3                             Продам кресло от0-25кг   2200.0   \n",
              "4                           Все вопросы по телефону.  40000.0   \n",
              "\n",
              "   item_seq_number activation_date user_type  \\\n",
              "0                2      2017-03-28   Private   \n",
              "1               19      2017-03-26   Private   \n",
              "2                9      2017-03-20   Private   \n",
              "3              286      2017-03-25   Company   \n",
              "4                3      2017-03-16   Private   \n",
              "\n",
              "                                               image  image_top_1  \\\n",
              "0  d10c7e016e03247a3bf2d13348fe959fe6f436c1caf64c...       1008.0   \n",
              "1  79c9392cc51a9c81c6eb91eceb8e552171db39d7142700...        692.0   \n",
              "2  b7f250ee3f39e1fedd77c141f273703f4a9be59db4b48a...       3032.0   \n",
              "3  e6ef97e0725637ea84e3d203e82dadb43ed3cc0a1c8413...        796.0   \n",
              "4  54a687a3a0fc1d68aed99bdaaf551c5c70b761b16fd0a2...       2264.0   \n",
              "\n",
              "   deal_probability  \n",
              "0           0.12789  \n",
              "1           0.00000  \n",
              "2           0.43177  \n",
              "3           0.80323  \n",
              "4           0.20797  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "rrEElmqbDFKC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "a586d813-de8e-4153-b658-9095abcf5172"
      },
      "cell_type": "code",
      "source": [
        "test_csv=pd.read_csv('/content/kaggle/test.csv.zip' , compression='zip' , header=0 , sep=',',quotechar='\"') \n",
        "test_csv.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>region</th>\n",
              "      <th>city</th>\n",
              "      <th>parent_category_name</th>\n",
              "      <th>category_name</th>\n",
              "      <th>param_1</th>\n",
              "      <th>param_2</th>\n",
              "      <th>param_3</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>price</th>\n",
              "      <th>item_seq_number</th>\n",
              "      <th>activation_date</th>\n",
              "      <th>user_type</th>\n",
              "      <th>image</th>\n",
              "      <th>image_top_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6544e41a8817</td>\n",
              "      <td>dbe73ad6e4b5</td>\n",
              "      <td>Волгоградская область</td>\n",
              "      <td>Волгоград</td>\n",
              "      <td>Личные вещи</td>\n",
              "      <td>Детская одежда и обувь</td>\n",
              "      <td>Для мальчиков</td>\n",
              "      <td>Обувь</td>\n",
              "      <td>25</td>\n",
              "      <td>Отдам бесплатно</td>\n",
              "      <td>На ангарском</td>\n",
              "      <td>NaN</td>\n",
              "      <td>66</td>\n",
              "      <td>2017-04-18</td>\n",
              "      <td>Private</td>\n",
              "      <td>a8b57acb5ab304f9c331ac7a074219aed4d349d8aef386...</td>\n",
              "      <td>2020.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>65b9484d670f</td>\n",
              "      <td>2e11806abe57</td>\n",
              "      <td>Свердловская область</td>\n",
              "      <td>Нижняя Тура</td>\n",
              "      <td>Хобби и отдых</td>\n",
              "      <td>Велосипеды</td>\n",
              "      <td>Дорожные</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Продам велосипед</td>\n",
              "      <td>Продам велосипед KAMA  F200,в нормальном состо...</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2017-04-16</td>\n",
              "      <td>Private</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8bab230b2ecd</td>\n",
              "      <td>0b850bbebb10</td>\n",
              "      <td>Новосибирская область</td>\n",
              "      <td>Бердск</td>\n",
              "      <td>Бытовая электроника</td>\n",
              "      <td>Аудио и видео</td>\n",
              "      <td>Телевизоры и проекторы</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>BBK</td>\n",
              "      <td>Продам новый телевизор BBK  32 диагональ смарт...</td>\n",
              "      <td>15000.0</td>\n",
              "      <td>15</td>\n",
              "      <td>2017-04-17</td>\n",
              "      <td>Private</td>\n",
              "      <td>8c361112cb049745ef2d1b0ae73594fc5c107286b0c942...</td>\n",
              "      <td>2960.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8e348601fefc</td>\n",
              "      <td>5f1d5c3ce0da</td>\n",
              "      <td>Саратовская область</td>\n",
              "      <td>Саратов</td>\n",
              "      <td>Для дома и дачи</td>\n",
              "      <td>Бытовая техника</td>\n",
              "      <td>Для кухни</td>\n",
              "      <td>Вытяжки</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Вытяжка Jetair 60</td>\n",
              "      <td>Продам новую вытяжку в упаковке,с документами....</td>\n",
              "      <td>4500.0</td>\n",
              "      <td>70</td>\n",
              "      <td>2017-04-17</td>\n",
              "      <td>Private</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8bd2fe400b89</td>\n",
              "      <td>23e2d97bfc7f</td>\n",
              "      <td>Оренбургская область</td>\n",
              "      <td>Бузулук</td>\n",
              "      <td>Личные вещи</td>\n",
              "      <td>Товары для детей и игрушки</td>\n",
              "      <td>Детские коляски</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Коляска зима-лето</td>\n",
              "      <td>Продам отличную коляску. б/у 1 год. все вопрос...</td>\n",
              "      <td>4900.0</td>\n",
              "      <td>15</td>\n",
              "      <td>2017-04-15</td>\n",
              "      <td>Private</td>\n",
              "      <td>bc3cf6deef10840fc302e38eb48fa7748aa1e28d534f8f...</td>\n",
              "      <td>1002.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        item_id       user_id                 region         city  \\\n",
              "0  6544e41a8817  dbe73ad6e4b5  Волгоградская область    Волгоград   \n",
              "1  65b9484d670f  2e11806abe57   Свердловская область  Нижняя Тура   \n",
              "2  8bab230b2ecd  0b850bbebb10  Новосибирская область       Бердск   \n",
              "3  8e348601fefc  5f1d5c3ce0da    Саратовская область      Саратов   \n",
              "4  8bd2fe400b89  23e2d97bfc7f   Оренбургская область      Бузулук   \n",
              "\n",
              "  parent_category_name               category_name                 param_1  \\\n",
              "0          Личные вещи      Детская одежда и обувь           Для мальчиков   \n",
              "1        Хобби и отдых                  Велосипеды                Дорожные   \n",
              "2  Бытовая электроника               Аудио и видео  Телевизоры и проекторы   \n",
              "3      Для дома и дачи             Бытовая техника               Для кухни   \n",
              "4          Личные вещи  Товары для детей и игрушки         Детские коляски   \n",
              "\n",
              "   param_2 param_3              title  \\\n",
              "0    Обувь      25    Отдам бесплатно   \n",
              "1      NaN     NaN   Продам велосипед   \n",
              "2      NaN     NaN                BBK   \n",
              "3  Вытяжки     NaN  Вытяжка Jetair 60   \n",
              "4      NaN     NaN  Коляска зима-лето   \n",
              "\n",
              "                                         description    price  \\\n",
              "0                                       На ангарском      NaN   \n",
              "1  Продам велосипед KAMA  F200,в нормальном состо...   3000.0   \n",
              "2  Продам новый телевизор BBK  32 диагональ смарт...  15000.0   \n",
              "3  Продам новую вытяжку в упаковке,с документами....   4500.0   \n",
              "4  Продам отличную коляску. б/у 1 год. все вопрос...   4900.0   \n",
              "\n",
              "   item_seq_number activation_date user_type  \\\n",
              "0               66      2017-04-18   Private   \n",
              "1                4      2017-04-16   Private   \n",
              "2               15      2017-04-17   Private   \n",
              "3               70      2017-04-17   Private   \n",
              "4               15      2017-04-15   Private   \n",
              "\n",
              "                                               image  image_top_1  \n",
              "0  a8b57acb5ab304f9c331ac7a074219aed4d349d8aef386...       2020.0  \n",
              "1                                                NaN          NaN  \n",
              "2  8c361112cb049745ef2d1b0ae73594fc5c107286b0c942...       2960.0  \n",
              "3                                                NaN          NaN  \n",
              "4  bc3cf6deef10840fc302e38eb48fa7748aa1e28d534f8f...       1002.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "RAqajseyQq92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "6456e40f-839f-4e04-dabb-1bda4b06dd79"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "notebookstart= time.time()\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import gc\n",
        "\n",
        "\n",
        "# Models Packages\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn import feature_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Gradient Boosting\n",
        "import lightgbm as lgb\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.cross_validation import KFold\n",
        "\n",
        "# Tf-Idf\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "from nltk.corpus import stopwords \n",
        "\n",
        "# Viz\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import string\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.1.1)\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.14.3)\r\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.19.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.19.1)\n",
            "[nltk_data] Downloading package stopwords to /content/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
            "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "QhECLczKRiCi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Funtion definition**  "
      ]
    },
    {
      "metadata": {
        "id": "P-7iLrMFQwTm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0bd00261-8d6a-4776-d984-960e175da014"
      },
      "cell_type": "code",
      "source": [
        "#@title functions\n",
        "NFOLDS = 5\n",
        "SEED = 42\n",
        "\n",
        "class SklearnWrapper(object):\n",
        "    def __init__(self, clf, seed=0, params=None, seed_bool = True):\n",
        "        if(seed_bool == True):\n",
        "            params['random_state'] = seed\n",
        "        self.clf = clf(**params)\n",
        "\n",
        "    def train(self, x_train, y_train):\n",
        "        self.clf.fit(x_train, y_train)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.clf.predict(x)\n",
        "        \n",
        "def get_oof(clf, x_train, y, x_test):\n",
        "    oof_train = np.zeros((ntrain,))\n",
        "    oof_test = np.zeros((ntest,))\n",
        "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
        "\n",
        "    for i, (train_index, test_index) in enumerate(kf):\n",
        "        print('\\nFold {}'.format(i))\n",
        "        x_tr = x_train[train_index]\n",
        "        y_tr = y[train_index]\n",
        "        x_te = x_train[test_index]\n",
        "\n",
        "        clf.train(x_tr, y_tr)\n",
        "\n",
        "        oof_train[test_index] = clf.predict(x_te)\n",
        "        oof_test_skf[i, :] = clf.predict(x_test)\n",
        "\n",
        "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
        "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n",
        "    \n",
        "def cleanName(text):\n",
        "    try:\n",
        "        textProc = text.lower()\n",
        "        textProc = \" \".join(map(str.strip, re.split('(\\d+)',textProc)))\n",
        "        regex = re.compile(u'[^[:alpha:]]')\n",
        "        textProc = regex.sub(\" \", textProc)\n",
        "        textProc = \" \".join(textProc.split())\n",
        "        return textProc\n",
        "    except: \n",
        "        return \"name error\"\n",
        "    \n",
        "    \n",
        "def rmse(y, y0):\n",
        "    assert len(y) == len(y0)\n",
        "    return np.sqrt(np.mean(np.power((y - y0), 2)))\n",
        "  \n",
        "def get_col(col_name): return lambda x: x[col_name]\n",
        "##I added to the max_features of the description. It did not change my score much but it may be worth investigating\n",
        "vectorizer = FeatureUnion([\n",
        "        ('description',TfidfVectorizer(\n",
        "            ngram_range=(1, 2),\n",
        "            max_features=17000,\n",
        "            **tfidf_para,\n",
        "            preprocessor=get_col('description'))),\n",
        "        ('title',CountVectorizer(\n",
        "            ngram_range=(1, 2),\n",
        "            stop_words = russian_stop,\n",
        "            #max_features=7000,\n",
        "            preprocessor=get_col('title')))\n",
        "    ])\n",
        "    \n",
        "  \n",
        "print(\"Functions defined\")\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Functions defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "79Mhe2tVPIk2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "b5317fc8-87c8-4803-99ea-3b3adccae4c6"
      },
      "cell_type": "code",
      "source": [
        "print(\"\\nData Load Stage\")\n",
        "training = pd.read_csv('/content/kaggle/train.csv.zip',compression='zip',header=0,sep=',',quotechar='\"', \n",
        "                       index_col = \"item_id\", parse_dates = [\"activation_date\"])\n",
        "traindex = training.index\n",
        "print(traindex)\n",
        "print('#####################################################################')\n",
        "testing = pd.read_csv('/content/kaggle/test.csv.zip',compression='zip',header=0,sep=',',quotechar='\"',\n",
        "                      index_col = \"item_id\", parse_dates = [\"activation_date\"])\n",
        "testdex = testing.index\n",
        "print(testdex)\n",
        "print('####################################################################')\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Data Load Stage\n",
            "Index(['b912c3c6a6ad', '2dac0150717d', 'ba83aefab5dc', '02996f1dd2ea',\n",
            "       '7c90be56d2ab', '51e0962387f7', 'c4f260a2b48a', '6b71309d6a8a',\n",
            "       'c5b969cb63a2', 'b1570962e68c',\n",
            "       ...\n",
            "       '72be5f7bac89', 'd4bf418c598e', 'a927b25d4daa', '21a474db168f',\n",
            "       '8ab4c1e56046', '5e6b7f0f3f65', 'd1f0910d2126', 'bc04866bc803',\n",
            "       'f782f2ad9349', '9ad3b7bff1db'],\n",
            "      dtype='object', name='item_id', length=1503424)\n",
            "#####################################################################\n",
            "Index(['6544e41a8817', '65b9484d670f', '8bab230b2ecd', '8e348601fefc',\n",
            "       '8bd2fe400b89', 'c63dbd6c657f', '6d1a410df86e', 'e8d3e7922b80',\n",
            "       '2bc1ab208462', '7e05d77a9181',\n",
            "       ...\n",
            "       '0915772bb21c', 'd8984ced6639', 'e7c68be28a03', 'a96a4c5ad75a',\n",
            "       'fdcd9910edf3', '9f2200aed300', '70813f518de4', 'a22a2eeb5dd2',\n",
            "       'ed7fbb0733c1', 'd374d332992f'],\n",
            "      dtype='object', name='item_id', length=508438)\n",
            "####################################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iA9PyqGKLV0t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1196
        },
        "outputId": "69ea8566-5cf4-4672-cc7a-0d9330b727dd"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "ntrain = training.shape[0]\n",
        "ntest = testing.shape[0]\n",
        "#cross validation\n",
        "kf = KFold(ntrain, n_folds=NFOLDS, shuffle=True, random_state=SEED)\n",
        "\n",
        "y = training.deal_probability.copy()\n",
        "print(y)\n",
        "training.drop(\"deal_probability\",axis=1, inplace=True)\n",
        "print('Train shape: {} Rows, {} Columns'.format(*training.shape))\n",
        "print('Test shape: {} Rows, {} Columns'.format(*testing.shape))\n",
        "\n",
        "print(\"Combine Train and Test\")\n",
        "df = pd.concat([training,testing],axis=0)\n",
        "del training, testing\n",
        "gc.collect()\n",
        "print('\\nAll Data shape: {} Rows, {} Columns'.format(*df.shape))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "item_id\n",
            "b912c3c6a6ad    0.12789\n",
            "2dac0150717d    0.00000\n",
            "ba83aefab5dc    0.43177\n",
            "02996f1dd2ea    0.80323\n",
            "7c90be56d2ab    0.20797\n",
            "51e0962387f7    0.80323\n",
            "c4f260a2b48a    0.00000\n",
            "6b71309d6a8a    0.80323\n",
            "c5b969cb63a2    0.00000\n",
            "b1570962e68c    0.00000\n",
            "d5480bb4a6e4    0.58853\n",
            "86f41f50d8c1    0.00000\n",
            "645237cb3601    0.13858\n",
            "df2116f34563    0.00000\n",
            "a97943ae8158    0.00000\n",
            "4b6abd0a5921    0.00000\n",
            "7896ef8fe482    0.32100\n",
            "7882b1e77748    0.00000\n",
            "071e1ed13c5c    0.00000\n",
            "0658628930d4    0.10342\n",
            "ea12aec32ec3    0.00000\n",
            "838a82cec0a6    0.00000\n",
            "de310e6aae86    0.10334\n",
            "08b24e170109    0.00000\n",
            "065a4daba35f    0.00000\n",
            "990113ae4f1c    0.10796\n",
            "78164bc09657    0.00000\n",
            "fbe29970a8a5    0.00000\n",
            "71d9399b59a2    0.00000\n",
            "4941f0385575    0.00000\n",
            "                 ...   \n",
            "c346749a7127    0.33720\n",
            "3c073bb117d8    0.00000\n",
            "6fcc0d49b22d    0.00000\n",
            "f7cb51309717    0.00000\n",
            "cb74d5fa1498    0.00000\n",
            "55760672b23e    0.00000\n",
            "15dc060224ab    0.00000\n",
            "87cb486a418d    0.14989\n",
            "5e317564107b    0.23044\n",
            "d630ca83fc9e    0.00000\n",
            "732b69fced92    0.01232\n",
            "fc8ff7c77732    0.00000\n",
            "bb532fcc7dec    0.86521\n",
            "ff2a88b765c6    0.00000\n",
            "d23a9e2a65e1    0.12384\n",
            "79386f3f2573    0.12459\n",
            "2bc8c895545b    0.00000\n",
            "43ad2ec1cd29    0.00000\n",
            "872691eb6232    0.00000\n",
            "00b6a41d5af9    0.00000\n",
            "72be5f7bac89    0.00000\n",
            "d4bf418c598e    0.00000\n",
            "a927b25d4daa    0.00000\n",
            "21a474db168f    0.73760\n",
            "8ab4c1e56046    0.12869\n",
            "5e6b7f0f3f65    0.25019\n",
            "d1f0910d2126    0.60000\n",
            "bc04866bc803    0.39569\n",
            "f782f2ad9349    0.00000\n",
            "9ad3b7bff1db    0.00000\n",
            "Name: deal_probability, Length: 1503424, dtype: float64\n",
            "Train shape: 1503424 Rows, 16 Columns\n",
            "Test shape: 508438 Rows, 16 Columns\n",
            "Combine Train and Test\n",
            "\n",
            "All Data shape: 2011862 Rows, 16 Columns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K3_ewdCPZJYy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Feature Extraction**"
      ]
    },
    {
      "metadata": {
        "id": "BAONWoobYawP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "df[\"price\"] = np.log(df[\"price\"]+0.001)\n",
        "df[\"price\"].fillna(-999,inplace=True)\n",
        "df[\"image_top_1\"].fillna(-999,inplace=True)\n",
        "\n",
        "print(\"Time_Variables\")\n",
        "df[\"Weekday\"] = df['activation_date'].dt.weekday\n",
        "df[\"Weekd of Year\"] = df['activation_date'].dt.week\n",
        "df[\"Day of Month\"] = df['activation_date'].dt.day\n",
        "\n",
        "# Create Validation Index and Remove Dead Variables\n",
        "training_index = df.loc[df.activation_date<=pd.to_datetime('2017-04-07')].index\n",
        "validation_index = df.loc[df.activation_date>=pd.to_datetime('2017-04-08')].index\n",
        "df.drop([\"activation_date\",\"image\"],axis=1,inplace=True)\n",
        "\n",
        "print(\"\\nEncode Variables\")\n",
        "categorical = [\"user_id\",\"region\",\"city\",\"parent_category_name\",\"category_name\",\"user_type\",\"image_top_1\",\"param_1\",\"param_2\",\"param_3\"]\n",
        "print(\"Encoding :\",categorical)\n",
        "\n",
        "# Encoder:\n",
        "lbl = preprocessing.LabelEncoder()\n",
        "for col in categorical:\n",
        "    df[col].fillna('Unknown')\n",
        "    df[col] = lbl.fit_transform(df[col].astype(str))\n",
        "    \n",
        "print(\"\\nText Features\")\n",
        "\n",
        "\n",
        "# Meta Text Features\n",
        "textfeats = [\"description\", \"title\"]\n",
        "\n",
        "# df['title'] = df['title'].apply(lambda x: cleanName(x))\n",
        "# df[\"description\"]   = df[\"description\"].apply(lambda x: cleanName(x))\n",
        "\n",
        "for cols in textfeats:\n",
        "    df[cols] = df[cols].astype(str) \n",
        "    df[cols] = df[cols].astype(str).fillna('missing') # FILL NA\n",
        "    df[cols] = df[cols].str.lower() # Lowercase all text, so that capitalized words dont get treated differently\n",
        "    df[cols + '_num_words'] = df[cols].apply(lambda comment: len(comment.split())) # Count number of Words\n",
        "    df[cols + '_num_unique_words'] = df[cols].apply(lambda comment: len(set(w for w in comment.split())))\n",
        "    df[cols + '_words_vs_unique'] = df[cols+'_num_unique_words'] / df[cols+'_num_words'] * 100 # Count Unique Words\n",
        "\n",
        "print(\"\\n[TF-IDF] Term Frequency Inverse Document Frequency Stage\")\n",
        "russian_stop = set(stopwords.words('russian'))\n",
        "\n",
        "tfidf_para = {\n",
        "    \"stop_words\": russian_stop,\n",
        "    \"analyzer\": 'word',\n",
        "    \"token_pattern\": r'\\w{1,}',\n",
        "    \"sublinear_tf\": True,\n",
        "    \"dtype\": np.float32,\n",
        "    \"norm\": 'l2',\n",
        "    #\"min_df\":5,\n",
        "    #\"max_df\":.9,\n",
        "    \"smooth_idf\":False\n",
        "}\n",
        "\n",
        "\n",
        "start_vect=time.time()\n",
        "\n",
        "#Fit my vectorizer on the entire dataset instead of the training rows\n",
        "#Score improved by .0001\n",
        "vectorizer.fit(df.to_dict('records'))\n",
        "\n",
        "ready_df = vectorizer.transform(df.to_dict('records'))\n",
        "tfvocab = vectorizer.get_feature_names()\n",
        "print(\"Vectorization Runtime: %0.2f Minutes\"%((time.time() - start_vect)/60))\n",
        "\n",
        "# Drop Text Cols\n",
        "textfeats = [\"description\", \"title\"]\n",
        "df.drop(textfeats, axis=1,inplace=True)\n",
        "\n",
        "ridge_params = {'alpha':2.0, 'fit_intercept':True, 'normalize':False, 'copy_X':True,\n",
        "                'max_iter':None, 'tol':0.001, 'solver':'auto', 'random_state':SEED}\n",
        "\n",
        "#Ridge oof method from Faron's kernel\n",
        "#I was using this to analyze my vectorization, but figured it would be interesting to add the results back into the dataset\n",
        "#It doesn't really add much to the score, but it does help lightgbm converge faster\n",
        "ridge = SklearnWrapper(clf=Ridge, seed = SEED, params = ridge_params)\n",
        "ridge_oof_train, ridge_oof_test = get_oof(ridge, ready_df[:ntrain], y, ready_df[ntrain:])\n",
        "\n",
        "rms = sqrt(mean_squared_error(y, ridge_oof_train))\n",
        "print('Ridge OOF RMSE: {}'.format(rms))\n",
        "\n",
        "print(\"Modeling Stage\")\n",
        "\n",
        "ridge_preds = np.concatenate([ridge_oof_train, ridge_oof_test])\n",
        "\n",
        "df['ridge_preds'] = ridge_preds\n",
        "\n",
        "# Combine Dense Features with Sparse Text Bag of Words Features\n",
        "X = hstack([csr_matrix(df.loc[traindex,:].values),ready_df[0:traindex.shape[0]]]) # Sparse Matrix\n",
        "testing = hstack([csr_matrix(df.loc[testdex,:].values),ready_df[traindex.shape[0]:]])\n",
        "tfvocab = df.columns.tolist() + tfvocab\n",
        "for shape in [X,testing]:\n",
        "    print(\"{} Rows and {} Cols\".format(*shape.shape))\n",
        "print(\"Feature Names Length: \",len(tfvocab))\n",
        "del df\n",
        "gc.collect();\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4_RKb2zoohq7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "2d62f1db-5ff2-4add-c0ae-39a6a6096eb1"
      },
      "cell_type": "code",
      "source": [
        "print(\"\\nModeling Stage\")\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.10, random_state=23)\n",
        "\n",
        "del ridge_preds,vectorizer,ready_df\n",
        "gc.collect();\n",
        "    \n",
        "print(\"Light Gradient Boosting Regressor\")\n",
        "lgbm_params =  {\n",
        "    'task': 'train',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    # 'max_depth': 15,\n",
        "    'num_leaves': 250,\n",
        "    'feature_fraction': 0.7,\n",
        "    'bagging_fraction': 0.85,\n",
        "    # 'bagging_freq': 5,\n",
        "    'learning_rate': 0.02,\n",
        "    'verbose': 0\n",
        "}  \n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Modeling Stage\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c46d9e70aac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nModeling Stage\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mridge_preds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mready_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "GlKg_kIaonwZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2679ad33-6d64-4390-a928-94632f2b025c"
      },
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "lgtrain = lgb.Dataset(X_train, y_train,\n",
        "                feature_name=tfvocab,\n",
        "                categorical_feature = categorical)\n",
        "lgvalid = lgb.Dataset(X_valid, y_valid,\n",
        "                feature_name=tfvocab,\n",
        "                categorical_feature = categorical)\n",
        "\n",
        "modelstart = time.time()\n",
        "lgb_clf = lgb.train(\n",
        "    lgbm_params,\n",
        "    lgtrain,\n",
        "    num_boost_round=16000,\n",
        "    valid_sets=[lgtrain, lgvalid],\n",
        "    valid_names=['train','valid'],\n",
        "    early_stopping_rounds=30,\n",
        "    verbose_eval=200\n",
        ")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
            "  warnings.warn('Using categorical_feature in Dataset.')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "--pqolc1ot2C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Feature Importance Plot\n",
        "f, ax = plt.subplots(figsize=[7,10])\n",
        "lgb.plot_importance(lgb_clf, max_num_features=50, ax=ax)\n",
        "plt.title(\"Light GBM Feature Importance\")\n",
        "plt.savefig('feature_import.png')\n",
        "\n",
        "print(\"Model Evaluation Stage\")\n",
        "lgpred = lgb_clf.predict(testing) \n",
        "\n",
        "#Mixing lightgbm with ridge. I haven't really tested if this improves the score or not\n",
        "#blend = 0.95*lgpred + 0.05*ridge_oof_test[:,0]\n",
        "lgsub = pd.DataFrame(lgpred,columns=[\"deal_probability\"],index=testdex)\n",
        "lgsub['deal_probability'].clip(0.0, 1.0, inplace=True) # Between 0 and 1\n",
        "lgsub.to_csv(\"lgsub.csv\",index=True,header=True)\n",
        "print(\"Model Runtime: %0.2f Minutes\"%((time.time() - modelstart)/60))\n",
        "print(\"Notebook Runtime: %0.2f Minutes\"%((time.time() - notebookstart)/60))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}